{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SGD\n",
    "\n",
    "Este notebook contem a implementação da regressão linear via gradiente descendente estocástico, desenvolvida para o curso CK0149 - GARIMPAGEM DE DADOS 2016.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Handler de dados\n",
    "\n",
    "Inicialmente devemos carregar os dados do dataset em uma matriz. Para isto, usaremos o NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17379"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed()\n",
    "\n",
    "data = np.loadtxt(\"bike_sharing.csv\", delimiter = ',')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos normalizar os dados e separá-los em k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findMinMax(dataset):\n",
    "    output = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        least = min(col_values)\n",
    "        maximum = max(col_values)\n",
    "        output.append([least, maximum])\n",
    "    return output\n",
    "\n",
    "def normalize(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row) - 1):\n",
    "            if not (minmax[i][0]==0 and minmax[i][1]==1):\n",
    "                row[i] = (row[i] - minmax[i][0])/(minmax[i][1] - minmax[i][0])\n",
    "            \n",
    "def kFoldSplit(dataset, k):\n",
    "    splitData = []\n",
    "    copy = list(dataset)\n",
    "    fold_size = len(dataset) / k\n",
    "    for i in range(k):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(copy))\n",
    "            fold.append(copy.pop(index))\n",
    "        splitData.append(fold)\n",
    "    return splitData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fazendo predições\n",
    "\n",
    "Ao completar a separação dos dados de treino e teste, devemos então iniciar a implementação do $SGD$. Para isso, precisamos inicialmente de um método para predizer a classe de um exemplo com base em no conjunto de coeficientes do nosso modelo. Dessa forma, criamos a função predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(example, coefficients):\n",
    "    y = coefficients[0]\n",
    "    \n",
    "    for i in range(len(example) - 1):\n",
    "        y += coefficients[i+1]*example[i]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimando os coeficientes do modelo\n",
    "\n",
    "Nosso modelo de predição é descrito em função de um conjunto de coeficientes, os quais são ajustados iterativamente durante a fase de treinamento. A função definida abaixo atualiza o valor dos coeficientes durante as épocas de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateCoefficients(trainingSet, alpha, epochs):\n",
    "    coef = [0.0 for i in range(len(trainingSet[0]))]\n",
    "    for epoch in range(epochs):\n",
    "        for row in trainingSet:\n",
    "            y = predict(row, coef)\n",
    "            \n",
    "            error = y - row[-1]\n",
    "            \n",
    "            coef[0] = coef[0] - alpha * error\n",
    "            \n",
    "            for i in range(len(row) - 1):\n",
    "                coef[i+1] = coef[i + 1] - alpha * error * row[i]\n",
    "    return coef        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regressão linear\n",
    "\n",
    "Agora que temos as funcoes de predição e de atualização dos coeficientes, podemos implementar a funcao principal da regressão linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linearRegression(train, test, alpha, epochs):\n",
    "    predictions = list()\n",
    "    output = {}\n",
    "    coef = updateCoefficients(train, alpha, epochs)\n",
    "    for row in test:\n",
    "        y = predict(row, coef)\n",
    "        predictions.append(y)\n",
    "    output.update({\"model\": coef, \"predictions\": predictions})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avaliando os resultados\n",
    "\n",
    "Agora precisamos de alguma métrica de avaliação do resultado obtido pelo algoritmo. Para isso, implementaremos uma função que calcula a raíz do erro quadrático médio e uma que avalia o algoritmo em si, utilizando os K Folds implementados acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanQuadraticError(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = actual[i] - predicted[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean = sum_error/float(len(actual))\n",
    "    \n",
    "    return math.sqrt(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(dataset, algorithm, nFolds, *args):\n",
    "    folds = kFoldSplit(dataset, nFolds)\n",
    "    foldPos = -1\n",
    "    output = {}\n",
    "    output.update({'folds': folds})\n",
    "    output.update({'actual': []})\n",
    "    output.update({'predicted': []})\n",
    "    output.update({'scores': []})\n",
    "    for fold in folds:\n",
    "        foldPos += 1\n",
    "        train_set = list(folds)\n",
    "        train_set.pop(foldPos)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        result = algorithm(train_set, test_set, *args)\n",
    "        predicted = result['predictions']\n",
    "        output.update({'model': result['model']})\n",
    "        actual = [row[-1] for row in fold]\n",
    "        rmse = meanQuadraticError(actual, predicted)\n",
    "        output['scores'].append(rmse)\n",
    "        output['predicted'].append(predicted)\n",
    "        output['actual'].append(actual)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Executando o algoritmo\n",
    "\n",
    "Agora devemos criar uma função main que chama as funções acima e calcula o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [8.024228329944282, 9.281614982929225, 6.599785374096325, 10.872708884767993, 8.674604719713221]\n"
     ]
    }
   ],
   "source": [
    "minmax = findMinMax(data)\n",
    "normalize(data, minmax)\n",
    "\n",
    "k = 5\n",
    "alpha = 1e-3\n",
    "epochs = 65\n",
    "output = evaluate(data, linearRegression, k, alpha, epochs)\n",
    "actual = output['actual']\n",
    "predicted = output['predicted']\n",
    "scores = output['scores']\n",
    "model = output['model']\n",
    "print('Scores: %s' % scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Métrica R²\n",
    "\n",
    "A métrica R² foi vista em classe e é uma boa maneira de avaliar o resultado. Abaixo, usando a implementação do scikit-learn dessa métrica, foi calculada a pontuação obtida ao usar cada fold como conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998040888973\n",
      "0.997330342553\n",
      "0.998702889885\n",
      "0.996407108131\n",
      "0.997696567792\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for i in range(len(actual)):\n",
    "    print metrics.r2_score(actual[i], predicted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dessa forma, podemos ver que os resultados preditos estão bem próximos dos resultados reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Questões propostas\n",
    "\n",
    "### a) Como você escolheu os parâmetros \"número de iterações\" e \"taxa de aprendizado\"? \n",
    "\n",
    "O número de iterações consiste do número de repetições (conhecidas como épocas de treinamento) que faremos do calculo dos coeficientes do modelo durante o processo de treinamento. Sabemos que o erro quadrático médio deve cair significativamente nas primeiras épocas de treinamento para então passar a ser praticamente constante. Nesse caso, devemos escolher um número de épocas que seja suficientemente grande para ultrapassar essa fase de queda do erro, uma vez que números de iterações maiores terão erros próximos. Dessa forma, após alguns testes, notou-se que 65 era um bom número.\n",
    "\n",
    "Já a taxa de aprendizado consiste do tamanho do passo que fazemos na direção do gradiente para se aproximar do mínimo da função de $erro$ $\\times$ $coeficientes$. Assim, se escolhermos taxas muito altas, podemos ultrapassar o ponto que queremos e nos afastar do mínimo, porém taxas baixas requerem mais épocas de treinamento, uma vez que a cada iteração se aproximam muito pouco do mínimo. Portanto, uma taxa que se adeque ao conjunto de dados é necessária, de modo que o modelo se atualize da forma desejada. Assim, concluiu-se após testes que 1e-3 era uma boa taxa.\n",
    "\n",
    "### b) Analise os resultados obtidos. O que o modelo diz sobre a importância de cada atributo?\n",
    "\n",
    "Abaixo seguem os valores dos coeficientes obtidos para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.037142561140993145,\n",
       " 0.19129688799843453,\n",
       " 0.58043562326005083,\n",
       " -0.040610625404925521,\n",
       " 1.2828199272820067,\n",
       " -0.13366038802548566,\n",
       " -0.27695403163458993,\n",
       " 0.12969200648077039,\n",
       " -0.28718810492919189,\n",
       " 2.2337569406171927,\n",
       " 0.87767930178240583,\n",
       " -1.1318287652372054,\n",
       " -0.38991376095354102,\n",
       " 366.38286262415107,\n",
       " 882.18020980267966]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto maiores os coeficientes, maior a importância daqueles atributos. Portanto, podemos notar que os dois últimos atributos são significativamente mais importantes para a regressão.\n",
    "\n",
    "### c) Compare com o resultado obtido pelo metodo dos minimos quadrados (do scikit-learn)\n",
    "\n",
    "Utilizaremos o linear_model do scikit-learn para efetuar a regressão do mesmo conjunto de dados e então comparar os resultados. Para simplificar, executamos a classificação novamente pelo algoritmo acima, agora com apenas um conjunto de treino e um de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "rand_data = np.random.permutation(data)\n",
    "\n",
    "sep = int(0.67*len(rand_data))\n",
    "\n",
    "train_datask = rand_data[:sep, :-1]\n",
    "test_datask = rand_data[sep:, :-1]\n",
    "\n",
    "yTrain_datask = rand_data[:sep, -1]\n",
    "yTest_datask = rand_data[sep:, -1]\n",
    "\n",
    "train_data = rand_data[:sep]\n",
    "test_data = rand_data[sep:]\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_datask, yTrain_datask)\n",
    "comparation = linearRegression(train_data, test_data, alpha, epochs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Regressao Linear implementada: ', 0.99799195941654528)\n",
      "('Regressao Linear do scikit-learn: ', 0.99799547525601673)\n"
     ]
    }
   ],
   "source": [
    "print(\"Regressao Linear implementada: \", metrics.r2_score(test_data[:,-1], comparation['predictions']))\n",
    "\n",
    "skpred = []\n",
    "for d in test_datask:\n",
    "    skpred.append(regr.predict(d))\n",
    "    \n",
    "print(\"Regressao Linear do scikit-learn: \", metrics.r2_score(rand_data[sep:, -1], skpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Como podemos ver, os dois modelos foram incrivelmente proximos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
